name: Transcribe audio to text (Whisper.cpp, nightly)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 4 * * *"   # 04:00 UTC = 22:00 MX Centro

jobs:
  transcribe:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Show env
        run: |
          echo "Node/ffmpeg will be installed; whisper.cpp with model 'small' (español)."

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install ffmpeg
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg
          node -v
          npm -v
          ffmpeg -version | head -n 1
          ffprobe -version | head -n 1

      - name: Install build deps (toolchain)
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential git curl ca-certificates

      # Cache del binario compilado y del modelo para acelerar corridas futuras
      - name: Cache whisper build
        id: cache-whisper-build
        uses: actions/cache@v4
        with:
          path: whisper.cpp/build-cache
          key: whisper-build-${{ runner.os }}-v1

      - name: Cache whisper model
        id: cache-whisper-model
        uses: actions/cache@v4
        with:
          path: whisper.cpp/models/ggml-small.bin
          key: whisper-model-small-v1

      - name: Clone & build whisper.cpp (detecta binario en build/bin)
        run: |
          set -euxo pipefail

          # Clonar si no existe
          if [ ! -d whisper.cpp ]; then
            git clone --depth=1 https://github.com/ggerganov/whisper.cpp.git
          fi

          cd whisper.cpp
          mkdir -p build-cache models

          # Descargar modelo 'small' con reintentos y fallback
          if [ ! -f models/ggml-small.bin ]; then
            echo "Descargando ggml-small.bin …"
            (curl -L --retry 5 --retry-delay 5 -o models/ggml-small.bin \
              https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.bin) \
              || (echo "HuggingFace falló, intento mirror…" && \
                  curl -L --retry 5 --retry-delay 5 -o models/ggml-small.bin \
                  https://github.com/ggerganov/whisper.cpp/releases/download/v1.5.5/ggml-small.bin)
          fi

          # Compilar con CMake a ./build
          cmake -B build -DCMAKE_BUILD_TYPE=Release
          cmake --build build --config Release -j2

          # Detectar binario: en versiones recientes queda en build/bin/{main|whisper-cli}
          BIN=""
          if [ -f build/bin/main ]; then
            BIN="build/bin/main"
          elif [ -f build/bin/whisper-cli ]; then
            BIN="build/bin/whisper-cli"
          else
            echo "No se encontró binario en build/bin. Listado de build:"
            ls -R build || true
            exit 1
          fi

          # Probar que corre
          "$BIN" -h | head -n 10 || true

          # Copiar a cache (ruta que usa el script transcribe.mjs)
          cp -f "$BIN" build-cache/main

          # Mostrar qué se generó
          ls -lh build-cache
          ls -lh models

          cd ..

      - name: Install Node deps (repo)
        run: |
          if [ -f package-lock.json ]; then
            npm ci
          else
            npm i --no-fund --no-audit
          fi

      - name: Run transcription (batch 20, lang=es, mark bad)
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          SUPABASE_BUCKET: audios
          SUPABASE_TABLE: recordings
          BATCH_LIMIT: "20"
          LANGUAGE: "es"
          MARK_BAD: "true"
          DRY_RUN: "false"
          WHISPER_BIN: "./whisper.cpp/build-cache/main"
          WHISPER_MODEL: "./whisper.cpp/models/ggml-small.bin"
        run: node scripts/transcribe.mjs
